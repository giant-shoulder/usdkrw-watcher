import requests
from bs4 import BeautifulSoup
import re
from datetime import datetime
import pytz

def fetch_expected_range():
    """
    ì—°í•©ì¸í¬ë§¥ìŠ¤ì—ì„œ 'ì˜¤ëŠ˜ ì™¸í™˜ë”œëŸ¬ í™˜ìœ¨ ì˜ˆìƒë ˆì¸ì§€' ê¸°ì‚¬ë¥¼ ìŠ¤í¬ë˜í•‘í•˜ì—¬
    ê°€ì¥ ë„“ì€ í™˜ìœ¨ ë²”ìœ„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    headers = {"User-Agent": "Mozilla/5.0"}
    search_url = (
        "https://news.einfomax.co.kr/news/articleList.html"
        "?sc_area=A&view_type=sm&sc_word=%ED%99%98%EC%9C%A8+%EC%98%88%EC%83%81+%EB%A0%88%EC%9D%B8%EC%A7%80"
    )

    # 1. ê¸°ì‚¬ ê²€ìƒ‰ í˜ì´ì§€ ìš”ì²­
    res = requests.get(search_url, headers=headers)
    res.raise_for_status()
    soup = BeautifulSoup(res.text, "html.parser")

    # 2. ìµœì‹  ê¸°ì‚¬ ë§í¬ ì¶”ì¶œ
    article_tag = soup.select_one("ul.type2 li a")
    if not article_tag or not article_tag.get("href"):
        raise ValueError("âŒ ê¸°ì‚¬ ë§í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    article_url = "https://news.einfomax.co.kr" + article_tag["href"]

    # 3. ê¸°ì‚¬ ë³¸ë¬¸ ìš”ì²­
    article_res = requests.get(article_url, headers=headers)
    article_res.raise_for_status()
    article_soup = BeautifulSoup(article_res.text, "html.parser")

    # 4. ê¸°ì‚¬ ë‚ ì§œ í™•ì¸
    meta_time = article_soup.find("meta", {"property": "article:published_time"})
    if not meta_time or not meta_time.get("content"):
        raise ValueError("âŒ ê¸°ì‚¬ ë‚ ì§œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    article_date = datetime.strptime(meta_time["content"].split("T")[0], "%Y-%m-%d").date()

    today = datetime.now(pytz.timezone("Asia/Seoul")).date()
    if article_date != today:
        raise ValueError(f"ğŸ“… ì˜¤ëŠ˜ ê¸°ì‚¬ ì•„ë‹˜: {article_date}")

    # 5. ì „ì²´ ê¸°ì‚¬ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    full_text = article_soup.get_text(separator="\n", strip=True)

    # 6. ì •ê·œì‹ìœ¼ë¡œ ì˜ˆìƒ ë ˆì¸ì§€ ì¶”ì¶œ (ì‰¼í‘œ í¬í•¨ ìˆ«ì ëŒ€ì‘)
    range_matches = re.findall(
        r"ì˜ˆìƒ\s*ë ˆì¸ì§€\s*[:ï¼š]?\s*([\d,\.]+)\s*[~\-]\s*([\d,\.]+)",
        full_text
    )
    if not range_matches:
        raise ValueError("âŒ ì˜ˆìƒ í™˜ìœ¨ ë²”ìœ„ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # 7. ì‰¼í‘œ ì œê±° ë° float ë³€í™˜
    ranges = []
    for low, high in range_matches:
        try:
            low_clean = float(low.replace(",", ""))
            high_clean = float(high.replace(",", ""))
            ranges.append((low_clean, high_clean))
        except ValueError:
            continue

    if not ranges:
        raise ValueError("âŒ ìœ íš¨í•œ ìˆ«ì í˜•ì‹ì˜ ë²”ìœ„ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    # 8. ê°€ì¥ ë„“ì€ ë²”ìœ„ ê³„ì‚°
    low = min(l for l, _ in ranges)
    high = max(h for _, h in ranges)

    print("âœ… ìŠ¤í¬ë˜í•‘ëœ ì˜ˆìƒ í™˜ìœ¨ ë ˆì¸ì§€:", ranges)

    return {
        "date": today,
        "low": low,
        "high": high,
        "source": article_url,
    }